{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e0c877-fdb1-4ff0-9b2e-1e7ade21e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats as st\n",
    "import glob\n",
    "import sklearn\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from datetime import date\n",
    "import sklearn.preprocessing as prepro\n",
    "import sklearn.cluster as cluster\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86838ef0-fc1b-487e-a50b-4e54625de5bc",
   "metadata": {},
   "source": [
    "This notebook works with pandas version 1.2.4 and sklearn version 0.24.2 Please check your requirements. Place ooportunity dataset files in a data folder. The header.csv file with this code contains the names of columns of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773091de-605d-415c-9f88-78a18a96c651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0345cb8-744c-45d7-a583-c555e9ea0d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05d88d9",
   "metadata": {},
   "source": [
    "# Dataset information\n",
    "This code uses the opportunity dataset that is available in the UCI ML repository. Please download from https://archive.ics.uci.edu/ml/datasets/OPPORTUNITY+Activity+Recognition and use in combination with the header.csv file provided with this code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecefe5d6",
   "metadata": {},
   "source": [
    "# Configuration options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0bc65d-b833-429f-aa84-4db997fc1b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', None)\n",
    "save_folder = 'data' # use to save results\n",
    "window_size = 30\n",
    "step = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label columns: 0: Locomotion, 1: HL_Activity, 2: LL_Left_Arm, 3: LL_Left_Arm_Object\n",
    "# 4: LL_Right_Arm, 5:LL_Right_Arm_Object, 6: ML_Both_Arms\n",
    "label_cols={'HL':1, 'LOC':0, 'LL_LeftArm':2, \"LL_LArm_Obj\":3, \"LL_RArm\":4, \"LL_RArm_Obj\":5, \"ML_BArms\":6}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3967cb92",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a9ccef2-8d2b-49e3-8d95-f739e0b619b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_opp_file(file):\n",
    "    header_path = 'header.csv'\n",
    "    header=pd.read_csv(header_path, sep='|', names=['column'])\n",
    "    header = header.column.str.replace(\",\",\"\")\n",
    "    data = pd.read_csv(file, sep=' ', header=None, names=header)\n",
    "    nan_ix = pd.isnull(data).sum(axis=1)>data.shape[1]*0.60 #more than 60% of columns are null in the row\n",
    "    data = data[~nan_ix]\n",
    "    data.loc[:,'MILLISEC']=pd.to_datetime(data.MILLISEC, unit='ms')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d12de725-4b9c-4296-81f1-7ef6eed578bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frame(data, user=\"user\", use_acc=\"\", label_column=0):\n",
    "    labels = data.iloc[:,243:]\n",
    "    labels = labels.iloc[:,label_column].astype('category')\n",
    "    data=data.iloc[:, :243]\n",
    "    columns_keep = list(filter(lambda x: ('acc' in x or 'gyro' in x or 'magnetic' in x) and use_acc in x, data.columns))\n",
    "    time = data[\"MILLISEC\"]\n",
    "    data = data[columns_keep]\n",
    "    #nan_ix = pd.isnull(data).sum(axis=1)>data.shape[1]*0.90 #more than 90% of columns are null in the row\n",
    "    #data = data[~nan_ix]\n",
    "    #time = time[~nan_ix]\n",
    "    #labels = labels[~nan_ix]\n",
    "    indexes = data.index\n",
    "    \n",
    "    #fill na\n",
    "    c = signal.savgol_filter(data, window_length=3, polyorder=2, axis=0, deriv=0)  \n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    c = imputer.fit_transform(c)\n",
    "    data = pd.DataFrame.from_records(c, columns=columns_keep, index=indexes)\n",
    "    \n",
    "    data['user'] = user\n",
    "    data['label'] = labels\n",
    "    data['MILLISEC'] = time\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e51bae-3e4d-430a-80f8-cfba86c65dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nulls(df):\n",
    "    df = df.fillna(method=\"bfill\")\n",
    "    df = df.fillna(method=\"ffill\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9026c8b-51bf-4b2b-ad81-abbabfb0237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(data, window_size=30, step=15):\n",
    "    '''\n",
    "    window size and step are in seconds\n",
    "    '''\n",
    "    data.index=data[\"MILLISEC\"]\n",
    "    \n",
    "    labels = data['label']\n",
    "    user = data['user'].unique()[0]\n",
    "    columns = data.columns[~data.columns.isin(['user', 'label', 'MILLISEC'])]\n",
    "    \n",
    "    keep = data[\"MILLISEC\"].dt.second % step \n",
    "    keep = keep - keep.shift() < 0\n",
    "    \n",
    "    wt = str(int(window_size))+\"S\"\n",
    "    means = data[columns].rolling(wt).mean()\n",
    "    means = fill_nulls(means)[keep]\n",
    "    means.columns = [str(col) + '_mean' for col in means.columns]\n",
    "    \n",
    "    variances = data[columns].rolling(wt).std()\n",
    "    variances = fill_nulls(variances)[keep]\n",
    "    variances.columns = [str(col) + '_var' for col in variances.columns]\n",
    "    \n",
    "    minimum = data[columns].rolling(wt).min()\n",
    "    minimum = fill_nulls(minimum)[keep]\n",
    "    maximum = data[columns].rolling(wt).max()\n",
    "    maximum = fill_nulls(maximum)[keep]\n",
    "    ranged = maximum - minimum\n",
    "    ranged.columns = [str(col) + '_range' for col in minimum.columns]\n",
    "    \n",
    "    medians = data[columns].rolling(wt).median()\n",
    "    medians = fill_nulls(medians)[keep]\n",
    "    medians = pd.DataFrame(medians.values, medians.index, columns=medians.columns)\n",
    "    medians.columns = [str(col) + '_median' for col in medians.columns] \n",
    "    \n",
    "    labels.index = data.index\n",
    "    mode_labels = labels.rolling(wt).apply(lambda x: st.mode(x)[0])[keep]\n",
    "    features = pd.concat([means, variances, ranged, medians, mode_labels], axis=1)\n",
    "    features['user']=user\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc56033-7664-4d24-af91-9b325dfc7635",
   "metadata": {},
   "source": [
    "# Read files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49f4818-f3f6-40dd-87ec-620e92e88cc2",
   "metadata": {},
   "source": [
    "## Read Additional data files\n",
    "\n",
    "Additional data consists of sensors not available in real conditions. Usually more sensors and of higher quality. We use InertialMeasurementUnit sensors as additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c36f9ef-c831-49a6-ba4f-bf0879cbc621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read filedata\\S1-Drill.dat\n",
      "Read filedata\\S2-Drill.dat\n",
      "Read filedata\\S3-Drill.dat\n",
      "Read filedata\\S4-Drill.dat\n",
      "Read filedata\\S1-ADL1.dat\n",
      "Read filedata\\S1-ADL2.dat\n",
      "Read filedata\\S1-ADL3.dat\n",
      "Read filedata\\S1-ADL4.dat\n",
      "Read filedata\\S1-ADL5.dat\n",
      "Read filedata\\S2-ADL1.dat\n",
      "Read filedata\\S2-ADL2.dat\n",
      "Read filedata\\S2-ADL3.dat\n",
      "Read filedata\\S2-ADL4.dat\n",
      "Read filedata\\S2-ADL5.dat\n",
      "Read filedata\\S3-ADL1.dat\n",
      "Read filedata\\S3-ADL2.dat\n",
      "Read filedata\\S3-ADL3.dat\n",
      "Read filedata\\S3-ADL4.dat\n",
      "Read filedata\\S3-ADL5.dat\n",
      "Read filedata\\S4-ADL1.dat\n",
      "Read filedata\\S4-ADL2.dat\n",
      "Read filedata\\S4-ADL3.dat\n",
      "Read filedata\\S4-ADL4.dat\n",
      "Read filedata\\S4-ADL5.dat\n"
     ]
    }
   ],
   "source": [
    "path = 'data/*-Drill.dat'\n",
    "files = glob.glob(path)\n",
    "drill_data = pd.DataFrame()\n",
    "use_acc = 'InertialMeasurementUnit'\n",
    "\n",
    "for file in files:\n",
    "    user = int(file[-11])\n",
    "    data = read_opp_file(file)\n",
    "    data = make_frame(data, use_acc=use_acc, user=user, label_column=1)\n",
    "    print(\"Read file\"+file)\n",
    "    features = make_features(data, window_size=window_size, step=step)\n",
    "    drill_data = pd.concat([drill_data, features])\n",
    "    \n",
    "path = 'data/*-ADL*.dat'\n",
    "files = glob.glob(path)\n",
    "for file in files:\n",
    "    user = int(file[-10])\n",
    "    data = read_opp_file(file)\n",
    "    print(\"Read file\"+file)\n",
    "    data = make_frame(data, use_acc=use_acc, user=user, label_column=1)\n",
    "    features = make_features(data, window_size=window_size, step=step)\n",
    "    drill_data = pd.concat([drill_data, features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dab4e9-fda0-4aaa-9ee7-00c48eb5b6a0",
   "metadata": {},
   "source": [
    "## Read Test data \n",
    "Test data is the data from real-life sensors. We use accelerometers. We use drill data only to learn the mapping functions from the real-life sensor to the data-space learned from additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90427814-25e4-410e-9d2f-0f72d7cec828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read filedata\\S1-ADL1.dat\n",
      "Read filedata\\S1-ADL2.dat\n",
      "Read filedata\\S1-ADL3.dat\n",
      "Read filedata\\S1-ADL4.dat\n",
      "Read filedata\\S1-ADL5.dat\n",
      "Read filedata\\S2-ADL1.dat\n",
      "Read filedata\\S2-ADL2.dat\n",
      "Read filedata\\S2-ADL3.dat\n",
      "Read filedata\\S2-ADL4.dat\n",
      "Read filedata\\S2-ADL5.dat\n",
      "Read filedata\\S3-ADL1.dat\n",
      "Read filedata\\S3-ADL2.dat\n",
      "Read filedata\\S3-ADL3.dat\n",
      "Read filedata\\S3-ADL4.dat\n",
      "Read filedata\\S3-ADL5.dat\n",
      "Read filedata\\S4-ADL1.dat\n",
      "Read filedata\\S4-ADL2.dat\n",
      "Read filedata\\S4-ADL3.dat\n",
      "Read filedata\\S4-ADL4.dat\n",
      "Read filedata\\S4-ADL5.dat\n",
      "Read filedata\\S1-Drill.dat\n",
      "Read filedata\\S2-Drill.dat\n",
      "Read filedata\\S3-Drill.dat\n",
      "Read filedata\\S4-Drill.dat\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.DataFrame()\n",
    "#ADL Data\n",
    "path = 'data/*-ADL*.dat'\n",
    "files = glob.glob(path)\n",
    "use_acc = 'BodyAccelerometer'\n",
    "for file in files:\n",
    "    user = int(file[-10])\n",
    "    data = read_opp_file(file)\n",
    "    print(\"Read file\"+file)\n",
    "    data = make_frame(data, use_acc=use_acc, user=user, label_column=1)\n",
    "    features = make_features(data, window_size=window_size, step=step)\n",
    "    all_data = pd.concat([all_data, features])\n",
    "    \n",
    "path = 'data/*-Drill.dat'\n",
    "files = glob.glob(path)\n",
    "mapping_data = pd.DataFrame()\n",
    "for file in files:\n",
    "    user = int(file[-11])\n",
    "    data = read_opp_file(file)\n",
    "    data = make_frame(data, use_acc=use_acc, user=user, label_column=1)\n",
    "    print(\"Read file\"+file)\n",
    "    features = make_features(data, window_size=window_size, step=step)\n",
    "    mapping_data = pd.concat([mapping_data, features])\n",
    "mapping_data = pd.concat([mapping_data, all_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53f873e-04e2-40a0-aa3a-101f1baab34b",
   "metadata": {},
   "source": [
    "# Train functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fa2b5c1-192d-4961-8a87-9d567510b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traditional_validation(X, y, users):\n",
    "    logo = LeaveOneGroupOut()\n",
    "    all_y_test = []\n",
    "    all_y_pred =[]\n",
    "    for train_index, test_index in logo.split(X, y, users):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = SVC(gamma='scale', class_weight='balanced').fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        all_y_test.extend(y_test)\n",
    "        all_y_pred.extend(pred)\n",
    "    return all_y_test, all_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "75731d90-de08-4a98-9087-a152c5e6c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_mapping_functions(tr_features, one_sensors_features, mapping_function, column, logistic): \n",
    "    z_train = np.copy(tr_features[:,column]).reshape(-1,1)\n",
    "    \n",
    "    # normarization function           \n",
    "    if logistic:\n",
    "        binarizer = prepro.Binarizer(threshold = np.median(z_train))\n",
    "        z_train = binarizer.fit_transform(z_train).ravel()\n",
    "        \n",
    "    mapping_function.fit(one_sensors_features, z_train) # learning\n",
    "    \"test mapping function\"\n",
    "    score = mapping_function.score(one_sensors_features, z_train)\n",
    "    return mapping_function, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "327adda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_proposed(one_acc_features, tr_features, mapping_features, labels_, users, mapping_function, logistic):\n",
    "    #train combined model\n",
    "    \n",
    "    the_labels_ = labels_\n",
    "    \n",
    "    logo = LeaveOneGroupOut()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "        \n",
    "    for train_index, test_index in logo.split(one_acc_features, the_labels_, users):\n",
    "        y_train, y_test = the_labels_[train_index], the_labels_[test_index]\n",
    "        x_train, x_test = np.copy(one_acc_features[train_index]), np.copy(one_acc_features[test_index])\n",
    "\n",
    "        \n",
    "        test_columns = np.empty((len(x_test),0))\n",
    "        train_columns = np.empty((len(x_train),0))\n",
    "\n",
    "        f_clf = SVC(gamma='scale', class_weight='balanced',probability =True)\n",
    "\n",
    "        scaler_x = prepro.StandardScaler()\n",
    "        x_train = scaler_x.fit_transform(x_train)\n",
    "        \n",
    "        scores = []\n",
    "        for column in range(tr_features.shape[1]):  #one classifier per column\n",
    "            mapping_function, score = fit_mapping_functions(tr_features, mapping_features, mapping_function, column, logistic)# learning\n",
    "            scores.append(score)\n",
    "            # evaluate train data\n",
    "            if logistic:\n",
    "                pred_col_t = mapping_function.predict_proba(x_train)[:,1].reshape(-1,1)\n",
    "            else:\n",
    "                pred_col_t = mapping_function.predict(x_train).reshape(-1,1)\n",
    "                \n",
    "            train_columns = np.hstack((train_columns, pred_col_t))\n",
    "\n",
    "            #evaluate test data\n",
    "            x_test = scaler_x.fit_transform(x_test)#fit and transform\n",
    "            if logistic:\n",
    "                pred_col = mapping_function.predict_proba(x_test)[:,1].reshape(-1,1)\n",
    "            else:\n",
    "                pred_col = mapping_function.predict(x_test).reshape(-1,1)\n",
    "\n",
    "            test_columns = np.hstack((test_columns, pred_col))\n",
    "        \n",
    "        \n",
    "        f_clf.fit(train_columns, y_train)#better to use train_columns as they are predicted\n",
    "        pred = f_clf.predict(test_columns)\n",
    "\n",
    "        y_true.extend(y_test)\n",
    "        y_pred.extend(pred)\n",
    "    return(y_true, y_pred, test_columns, np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5210df7a-cfdf-40bc-9e96-137ca6d02f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_proposed_boosted(one_acc_features, tr_features, mapping_features, labels_, users, mapping_function, logistic):\n",
    "    #train combined model\n",
    "    le = prepro.LabelEncoder()\n",
    "    the_labels_ = le.fit_transform(labels_)\n",
    "    \n",
    "    logo = LeaveOneGroupOut()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for train_index, test_index in logo.split(one_acc_features, the_labels_, users):\n",
    "        y_train, y_test = the_labels_[train_index], the_labels_[test_index]\n",
    "        x_train, x_test = np.copy(one_acc_features[train_index]), np.copy(one_acc_features[test_index])\n",
    "        \n",
    "        #one classifier per column\n",
    "        test_columns = np.empty((len(x_test),0))\n",
    "        train_columns = np.empty((len(x_train),0))\n",
    "\n",
    "        f_clf = SVC(gamma='scale', class_weight='balanced', probability=True)\n",
    "\n",
    "        scaler_x = prepro.StandardScaler()\n",
    "        x_train = scaler_x.fit_transform(x_train)\n",
    "        \n",
    "        scores = []\n",
    "\n",
    "        for column in range(tr_features.shape[1]):\n",
    "            mapping_function, score = fit_mapping_functions(tr_features, mapping_features, mapping_function, column, logistic)# learning\n",
    "            scores.append(score)\n",
    "            #evaluate train data\n",
    "            if logistic:\n",
    "                pred_col_t = mapping_function.predict_proba(x_train)[:,1].reshape(-1,1)\n",
    "            else:\n",
    "                pred_col_t = mapping_function.predict(x_train).reshape(-1,1)\n",
    "            train_columns = np.hstack((train_columns, pred_col_t))\n",
    "\n",
    "            #evaluate test data\n",
    "            x_test = scaler_x.fit_transform(x_test)\n",
    "            if logistic:\n",
    "                pred_col = mapping_function.predict_proba(x_test)[:,1].reshape(-1,1)\n",
    "            else:\n",
    "                pred_col = mapping_function.predict(x_test).reshape(-1,1)\n",
    "\n",
    "            test_columns = np.hstack((test_columns, pred_col))\n",
    "\n",
    "        k = len(np.unique(labels_))\n",
    "        w_1 = np.full([len(x_train), ], 1/k)\n",
    "        \n",
    "\n",
    "        f_clf.fit(train_columns, y_train, sample_weight= w_1)\n",
    "            \n",
    "       \n",
    "        predicted = f_clf.predict(train_columns)\n",
    "        errors_cluster_model = predicted != y_train\n",
    "        \n",
    "        err_1 = np.mean(np.average(errors_cluster_model, axis=0, weights=w_1))\n",
    "        alpha_1 = np.log((1-err_1)/err_1)+ np.log (k-1)\n",
    "        w_2 = w_1 * np.exp(alpha_1*errors_cluster_model)\n",
    "        \n",
    "        \n",
    "        estimators = []\n",
    "        estimators.append(('standardize', prepro.StandardScaler()))\n",
    "        estimators.append(('clf', SVC(gamma='scale', probability=True, class_weight='balanced')))\n",
    "        acc_model = Pipeline(estimators)\n",
    "        \n",
    "        acc_model.fit(x_train, y_train, **{'clf__sample_weight': w_2})\n",
    "        \n",
    "        predicted_acc = acc_model.predict(x_train)\n",
    "        errors_acc = predicted_acc != y_train\n",
    "        \n",
    "        err_2 = np.mean(np.average(errors_acc, axis=0, weights=w_2))\n",
    "        alpha_2 = np.log((1-err_2)/err_2)+ np.log (k-1) ### \n",
    "        \n",
    "        \n",
    "        t2_x = acc_model.predict_proba(x_test)\n",
    "        t1_x = f_clf.predict_proba(test_columns)\n",
    "        #get arg max\n",
    "        sum_output = alpha_1*t1_x + alpha_2*t2_x\n",
    "        pred = np.argmax(sum_output, axis=1)\n",
    "    \n",
    "        y_true.extend(y_test.astype(int))\n",
    "        y_pred.extend(pred)\n",
    "        \n",
    "    return(y_true, y_pred, np.mean(scores) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1acbcbc5-2c82-4f31-8649-bde0cfd47c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_proposed_features(X_add, n_clusters=None):\n",
    "    scale = prepro.StandardScaler()\n",
    "    X_feat = scale.fit_transform(X_add)\n",
    "    cluster_model= None\n",
    "    if n_clusters is None:\n",
    "        dist = euclidean_distances(X_feat)\n",
    "        d_threshold = np.std(dist)\n",
    "        cluster_model = cluster.FeatureAgglomeration(distance_threshold=d_threshold, n_clusters=None, compute_full_tree=True)\n",
    "    else:\n",
    "        cluster_model = cluster.FeatureAgglomeration(distance_threshold=None, n_clusters=n_clusters, compute_full_tree=None)\n",
    "    # normalization\n",
    "    tr_features = cluster_model.fit_transform(X_feat)\n",
    "    return scale, tr_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c9f513-51b3-45ba-bc37-0c85afc16f05",
   "metadata": {},
   "source": [
    "# Train traditional approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2baeb9bb-9ddb-421f-b846-4266cb736a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 11\n",
    "test_sensors = ['HIP', 'BACK', 'LUA_', 'RUA_', 'LUA^', 'RUA^', 'LWR', 'RWR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68bee619-53fd-49bb-9766-403316bbc0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = repr(str(date.today()))+'_'+str(trial)+'_traditional_results.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eee9b2ad-c487-48dd-a4bb-1ac6c8490c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional ALL Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.32      0.45       215\n",
      "       101.0       0.66      0.62      0.64       103\n",
      "       102.0       0.41      0.64      0.50       195\n",
      "       103.0       0.75      0.66      0.70       310\n",
      "       104.0       0.36      0.80      0.50       190\n",
      "       105.0       0.86      0.50      0.63       394\n",
      "\n",
      "    accuracy                           0.58      1407\n",
      "   macro avg       0.64      0.59      0.57      1407\n",
      "weighted avg       0.68      0.58      0.59      1407\n",
      "\n",
      "Traditional HIP Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.24      0.27       215\n",
      "       101.0       0.78      0.67      0.72       103\n",
      "       102.0       0.33      0.48      0.39       195\n",
      "       103.0       0.49      0.58      0.53       310\n",
      "       104.0       0.33      0.54      0.41       190\n",
      "       105.0       0.61      0.31      0.41       394\n",
      "\n",
      "    accuracy                           0.44      1407\n",
      "   macro avg       0.48      0.47      0.46      1407\n",
      "weighted avg       0.48      0.44      0.44      1407\n",
      "\n",
      "Traditional BACK Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.37      0.45       215\n",
      "       101.0       0.45      0.59      0.51       103\n",
      "       102.0       0.22      0.19      0.20       195\n",
      "       103.0       0.50      0.63      0.56       310\n",
      "       104.0       0.45      0.70      0.55       190\n",
      "       105.0       0.61      0.42      0.50       394\n",
      "\n",
      "    accuracy                           0.48      1407\n",
      "   macro avg       0.46      0.48      0.46      1407\n",
      "weighted avg       0.49      0.48      0.47      1407\n",
      "\n",
      "Traditional LUA_ Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.48      0.44       215\n",
      "       101.0       0.51      0.36      0.42       103\n",
      "       102.0       0.29      0.30      0.29       195\n",
      "       103.0       0.54      0.59      0.57       310\n",
      "       104.0       0.31      0.45      0.37       190\n",
      "       105.0       0.79      0.51      0.62       394\n",
      "\n",
      "    accuracy                           0.48      1407\n",
      "   macro avg       0.47      0.45      0.45      1407\n",
      "weighted avg       0.52      0.48      0.49      1407\n",
      "\n",
      "Traditional RUA_ Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.42      0.48       215\n",
      "       101.0       0.13      0.28      0.18       103\n",
      "       102.0       0.23      0.30      0.26       195\n",
      "       103.0       0.44      0.42      0.43       310\n",
      "       104.0       0.28      0.37      0.32       190\n",
      "       105.0       0.77      0.42      0.54       394\n",
      "\n",
      "    accuracy                           0.39      1407\n",
      "   macro avg       0.40      0.37      0.37      1407\n",
      "weighted avg       0.48      0.39      0.41      1407\n",
      "\n",
      "Traditional LUA^ Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.33      0.43       215\n",
      "       101.0       0.55      0.79      0.65       103\n",
      "       102.0       0.34      0.47      0.39       195\n",
      "       103.0       0.49      0.46      0.48       310\n",
      "       104.0       0.25      0.46      0.32       190\n",
      "       105.0       0.74      0.43      0.55       394\n",
      "\n",
      "    accuracy                           0.46      1407\n",
      "   macro avg       0.50      0.49      0.47      1407\n",
      "weighted avg       0.53      0.46      0.47      1407\n",
      "\n",
      "Traditional RUA^ Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.28      0.32       215\n",
      "       101.0       0.33      0.62      0.43       103\n",
      "       102.0       0.25      0.37      0.30       195\n",
      "       103.0       0.43      0.30      0.35       310\n",
      "       104.0       0.28      0.63      0.39       190\n",
      "       105.0       0.65      0.18      0.28       394\n",
      "\n",
      "    accuracy                           0.34      1407\n",
      "   macro avg       0.38      0.40      0.34      1407\n",
      "weighted avg       0.43      0.34      0.33      1407\n",
      "\n",
      "Traditional LWR Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.39      0.20      0.26       215\n",
      "       101.0       0.29      0.52      0.38       103\n",
      "       102.0       0.20      0.12      0.15       195\n",
      "       103.0       0.46      0.60      0.52       310\n",
      "       104.0       0.28      0.56      0.37       190\n",
      "       105.0       0.85      0.43      0.57       394\n",
      "\n",
      "    accuracy                           0.41      1407\n",
      "   macro avg       0.41      0.41      0.38      1407\n",
      "weighted avg       0.48      0.41      0.41      1407\n",
      "\n",
      "Traditional RWR Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.31      0.40       215\n",
      "       101.0       0.09      0.33      0.15       103\n",
      "       102.0       0.31      0.39      0.35       195\n",
      "       103.0       0.62      0.56      0.59       310\n",
      "       104.0       0.28      0.27      0.27       190\n",
      "       105.0       0.78      0.42      0.55       394\n",
      "\n",
      "    accuracy                           0.41      1407\n",
      "   macro avg       0.44      0.38      0.38      1407\n",
      "weighted avg       0.53      0.41      0.44      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_file=open(save_folder+save_file, \"wt\")\n",
    "print(date.today(), file=results_file)\n",
    "print(\"-----------\", file=results_file)\n",
    "print(f\"Using {window_size} and {step}\", file=results_file)\n",
    "\n",
    "#Train with all sensors\n",
    "users = all_data['user'].values\n",
    "Y = all_data['label'].values\n",
    "X = all_data.drop(['user', 'label'], axis=1).values\n",
    "y_test, y_pred = traditional_validation(X, Y, users)\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "print(f'Traditional ALL Report')\n",
    "print(report)\n",
    "print (f'Traditional ALLReport \\r\\n {report}', file=results_file)\n",
    "print(\"-----------END-----------\", file=results_file)\n",
    "\n",
    "for sensor in test_sensors:\n",
    "    columns = list(filter(lambda x: sensor in x,all_data.columns))\n",
    "    users = all_data['user'].values\n",
    "    Y = all_data['label'].values\n",
    "    X = all_data[columns].values\n",
    "    y_test, y_pred = traditional_validation(X, Y, users)\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    print(f'Traditional {sensor} Report')\n",
    "    print(report)\n",
    "    print (f'Traditional {sensor} Report \\r\\n {report}', file=results_file)\n",
    "    print(\"-----------END-----------\", file=results_file)\n",
    "results_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b59c2e2-514d-4cfd-a783-8b5b6963abc6",
   "metadata": {},
   "source": [
    "# Train proposed approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "34250fa6-517d-43b0-a901-c2d27cf31458",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = repr(str(date.today()))+'_'+str(trial)+'_proposed_results.txt'\n",
    "results_file=open(save_folder+save_file, \"wt\")\n",
    "print(date.today(), file=results_file)\n",
    "print(\"-----------\", file=results_file)\n",
    "print(f\"Using {window_size} and {step}\", file=results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4ddbafee-3cbd-43d8-a789-2a9a0fd7c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    " #make cluster features\n",
    "all_features = drill_data.drop(['user', 'label'], axis=1).reset_index(drop=True)\n",
    "all_features = pd.concat([all_features,mapping_data.drop(['user', 'label'], axis=1).reset_index(drop=True)], axis=1, ignore_index=True)\n",
    "all_features.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "902048c9-43e5-4dd4-a385-af9409c5dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale, tr_features  = make_proposed_features(all_features.values, n_clusters=30) #using 30\n",
    "print(f\"Using {tr_features.shape[1]} clusters\", file=results_file)\n",
    "print(\"-----------\", file=results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ff16b951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1901, 30)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6a45cd63-cf4d-4579-993f-82644526f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c9133344-14da-485a-af6a-dca548cf7dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usingRUA^\n",
      "0.3453761155034671\n",
      "Proposed Boosted RUA^\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.34      0.34       215\n",
      "           1       0.69      0.64      0.66       103\n",
      "           2       0.45      0.15      0.22       195\n",
      "           3       0.55      0.65      0.60       310\n",
      "           4       0.42      0.30      0.35       190\n",
      "           5       0.52      0.69      0.59       394\n",
      "\n",
      "    accuracy                           0.50      1407\n",
      "   macro avg       0.49      0.46      0.46      1407\n",
      "weighted avg       0.49      0.50      0.48      1407\n",
      "\n",
      "0.3453761155034671\n",
      "Proposed  RUA^\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.45      0.45       215\n",
      "       101.0       0.70      0.68      0.69       103\n",
      "       102.0       0.33      0.39      0.36       195\n",
      "       103.0       0.78      0.58      0.66       310\n",
      "       104.0       0.39      0.74      0.51       190\n",
      "       105.0       0.70      0.48      0.57       394\n",
      "\n",
      "    accuracy                           0.53      1407\n",
      "   macro avg       0.56      0.55      0.54      1407\n",
      "weighted avg       0.59      0.53      0.54      1407\n",
      "\n",
      "usingLUA^\n",
      "0.3483708548428098\n",
      "Proposed Boosted LUA^\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.57      0.52       215\n",
      "           1       0.74      0.58      0.65       103\n",
      "           2       0.56      0.29      0.39       195\n",
      "           3       0.64      0.72      0.67       310\n",
      "           4       0.44      0.38      0.41       190\n",
      "           5       0.60      0.70      0.65       394\n",
      "\n",
      "    accuracy                           0.58      1407\n",
      "   macro avg       0.58      0.54      0.55      1407\n",
      "weighted avg       0.57      0.58      0.57      1407\n",
      "\n",
      "0.3483708548428098\n",
      "Proposed  LUA^\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.49      0.49       215\n",
      "       101.0       0.71      0.61      0.66       103\n",
      "       102.0       0.36      0.50      0.42       195\n",
      "       103.0       0.82      0.65      0.73       310\n",
      "       104.0       0.38      0.64      0.47       190\n",
      "       105.0       0.82      0.55      0.66       394\n",
      "\n",
      "    accuracy                           0.57      1407\n",
      "   macro avg       0.60      0.57      0.57      1407\n",
      "weighted avg       0.64      0.57      0.59      1407\n",
      "\n",
      "usingHIP\n",
      "0.2974075888685753\n",
      "Proposed Boosted HIP\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.24      0.30       215\n",
      "           1       0.85      0.86      0.86       103\n",
      "           2       0.11      0.04      0.05       195\n",
      "           3       0.63      0.76      0.69       310\n",
      "           4       0.54      0.46      0.49       190\n",
      "           5       0.46      0.68      0.55       394\n",
      "\n",
      "    accuracy                           0.52      1407\n",
      "   macro avg       0.50      0.51      0.49      1407\n",
      "weighted avg       0.48      0.52      0.49      1407\n",
      "\n",
      "0.2974075888685753\n",
      "Proposed  HIP\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.38      0.39       215\n",
      "       101.0       0.82      0.89      0.86       103\n",
      "       102.0       0.29      0.44      0.35       195\n",
      "       103.0       0.78      0.68      0.73       310\n",
      "       104.0       0.43      0.65      0.51       190\n",
      "       105.0       0.54      0.33      0.41       394\n",
      "\n",
      "    accuracy                           0.51      1407\n",
      "   macro avg       0.55      0.56      0.54      1407\n",
      "weighted avg       0.54      0.51      0.52      1407\n",
      "\n",
      "usingLWR\n",
      "0.41261129067821134\n",
      "Proposed Boosted LWR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.54      0.51       215\n",
      "           1       0.41      0.26      0.32       103\n",
      "           2       0.36      0.11      0.17       195\n",
      "           3       0.63      0.72      0.67       310\n",
      "           4       0.41      0.27      0.33       190\n",
      "           5       0.57      0.81      0.67       394\n",
      "\n",
      "    accuracy                           0.54      1407\n",
      "   macro avg       0.48      0.45      0.44      1407\n",
      "weighted avg       0.51      0.54      0.50      1407\n",
      "\n",
      "0.41261129067821134\n",
      "Proposed  LWR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.57      0.53       215\n",
      "       101.0       0.27      0.29      0.28       103\n",
      "       102.0       0.36      0.35      0.36       195\n",
      "       103.0       0.71      0.65      0.68       310\n",
      "       104.0       0.38      0.63      0.47       190\n",
      "       105.0       0.76      0.52      0.62       394\n",
      "\n",
      "    accuracy                           0.53      1407\n",
      "   macro avg       0.50      0.50      0.49      1407\n",
      "weighted avg       0.57      0.53      0.54      1407\n",
      "\n",
      "usingRWR\n",
      "0.307006928595275\n",
      "Proposed Boosted RWR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.55      0.47       215\n",
      "           1       0.10      0.12      0.10       103\n",
      "           2       0.18      0.12      0.15       195\n",
      "           3       0.48      0.53      0.50       310\n",
      "           4       0.36      0.19      0.25       190\n",
      "           5       0.57      0.60      0.59       394\n",
      "\n",
      "    accuracy                           0.42      1407\n",
      "   macro avg       0.35      0.35      0.34      1407\n",
      "weighted avg       0.41      0.42      0.41      1407\n",
      "\n",
      "0.307006928595275\n",
      "Proposed  RWR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.39      0.59      0.47       215\n",
      "       101.0       0.04      0.10      0.06       103\n",
      "       102.0       0.30      0.31      0.30       195\n",
      "       103.0       0.78      0.40      0.53       310\n",
      "       104.0       0.33      0.47      0.39       190\n",
      "       105.0       0.80      0.40      0.53       394\n",
      "\n",
      "    accuracy                           0.40      1407\n",
      "   macro avg       0.44      0.38      0.38      1407\n",
      "weighted avg       0.54      0.40      0.43      1407\n",
      "\n",
      "usingRUA_\n",
      "0.3092205349879206\n",
      "Proposed Boosted RUA_\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.68      0.54       215\n",
      "           1       0.60      0.40      0.48       103\n",
      "           2       0.48      0.20      0.28       195\n",
      "           3       0.60      0.71      0.65       310\n",
      "           4       0.40      0.26      0.32       190\n",
      "           5       0.64      0.72      0.68       394\n",
      "\n",
      "    accuracy                           0.56      1407\n",
      "   macro avg       0.53      0.50      0.49      1407\n",
      "weighted avg       0.55      0.56      0.53      1407\n",
      "\n",
      "0.3092205349879206\n",
      "Proposed  RUA_\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.55      0.51       215\n",
      "       101.0       0.41      0.57      0.48       103\n",
      "       102.0       0.29      0.42      0.34       195\n",
      "       103.0       0.73      0.60      0.66       310\n",
      "       104.0       0.41      0.54      0.47       190\n",
      "       105.0       0.79      0.44      0.56       394\n",
      "\n",
      "    accuracy                           0.51      1407\n",
      "   macro avg       0.52      0.52      0.50      1407\n",
      "weighted avg       0.58      0.51      0.53      1407\n",
      "\n",
      "usingLUA_\n",
      "0.36330427803292287\n",
      "Proposed Boosted LUA_\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.61      0.52       215\n",
      "           1       0.75      0.43      0.54       103\n",
      "           2       0.34      0.11      0.17       195\n",
      "           3       0.64      0.81      0.71       310\n",
      "           4       0.46      0.27      0.34       190\n",
      "           5       0.62      0.78      0.69       394\n",
      "\n",
      "    accuracy                           0.57      1407\n",
      "   macro avg       0.54      0.50      0.50      1407\n",
      "weighted avg       0.55      0.57      0.54      1407\n",
      "\n",
      "0.36330427803292287\n",
      "Proposed  LUA_\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.59      0.53       215\n",
      "       101.0       0.64      0.56      0.60       103\n",
      "       102.0       0.33      0.40      0.36       195\n",
      "       103.0       0.77      0.73      0.75       310\n",
      "       104.0       0.36      0.54      0.43       190\n",
      "       105.0       0.85      0.53      0.65       394\n",
      "\n",
      "    accuracy                           0.57      1407\n",
      "   macro avg       0.57      0.56      0.56      1407\n",
      "weighted avg       0.62      0.57      0.58      1407\n",
      "\n",
      "usingBACK\n",
      "0.29253166679259135\n",
      "Proposed Boosted BACK\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       215\n",
      "           1       0.67      0.63      0.65       103\n",
      "           2       0.25      0.01      0.02       195\n",
      "           3       0.55      0.66      0.60       310\n",
      "           4       0.62      0.51      0.56       190\n",
      "           5       0.48      0.68      0.56       394\n",
      "\n",
      "    accuracy                           0.54      1407\n",
      "   macro avg       0.53      0.51      0.50      1407\n",
      "weighted avg       0.51      0.54      0.51      1407\n",
      "\n",
      "0.29253166679259135\n",
      "Proposed  BACK\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.60      0.60       215\n",
      "       101.0       0.67      0.64      0.66       103\n",
      "       102.0       0.28      0.39      0.33       195\n",
      "       103.0       0.73      0.65      0.69       310\n",
      "       104.0       0.45      0.77      0.57       190\n",
      "       105.0       0.69      0.39      0.50       394\n",
      "\n",
      "    accuracy                           0.55      1407\n",
      "   macro avg       0.57      0.57      0.56      1407\n",
      "weighted avg       0.60      0.55      0.55      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sensors = ['RUA^', 'LUA^', 'HIP',  'LWR', 'RWR', 'RUA_', 'LUA_', 'BACK']\n",
    "for sensor in test_sensors:\n",
    "    columns = list(filter(lambda x: sensor in x,all_data.columns))\n",
    "    users = all_data['user'].values\n",
    "    Y = all_data['label'].values\n",
    "    one_sensor_X= all_data[columns].values\n",
    "    \n",
    "    print(f\"using{sensor}\")\n",
    "    mapping_features = mapping_data[columns] #using data from drill and adl files but same sensor as test sensor. \n",
    "    scale = prepro.StandardScaler()\n",
    "    mapping_features = scale.fit_transform(mapping_features)\n",
    "    \n",
    "    #train proposed\n",
    "    #mapping_function = lm.LogisticRegression(solver=\"lbfgs\", max_iter=100000) #for logistic regression\n",
    "    mapping_function = SVR(kernel=\"linear\", C=1.0, epsilon=0.00001) #for linear regression, epsilon is small as values of features are small\n",
    "    y_true, y_pred, mean_score = train_test_proposed_boosted(one_sensor_X,  tr_features, mapping_features, Y, users, mapping_function, False)\n",
    "    print(mean_score)\n",
    "    print(f\"Proposed Boosted {sensor}\")\n",
    "    report = classification_report(y_true, y_pred, zero_division=0)\n",
    "    print(report)\n",
    "    print(f'Proposed Boosted {sensor} Report \\r\\n {report}', file=results_file)\n",
    "    \n",
    "    #mapping_function = lm.LogisticRegression(solver=\"lbfgs\", max_iter=100000)#for logistic regression\n",
    "    y_true, y_pred, test_col, mean_score = train_test_proposed(one_sensor_X, tr_features, mapping_features, Y, users, mapping_function, False)\n",
    "    print(mean_score)\n",
    "    print(f\"Proposed  {sensor}\")\n",
    "    report = classification_report(y_true, y_pred, zero_division=0)\n",
    "    print(report)\n",
    "    print(f'Proposed  {sensor} Report \\r\\n {report}', file=results_file)\n",
    "    \n",
    "    \n",
    "results_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db82a4-1ce3-48e9-9ef9-6fbcaf0f6be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_all = drill_data['label']\n",
    "u_all = drill_data['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef92efc-593b-47fe-85f1-574dfc45b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, y_pred = traditional_validation(tr_features, l_all, u_all)\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "print(f'tr_features ALL Report')\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
